import numpy as np
import pandas as pd
from sklearn.ensemble import RandomForestRegressor
from sklearn.model_selection import train_test_split
from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score
from sklearn.preprocessing import StandardScaler
import xgboost as xgb
import joblib
import os
import logging
from datetime import datetime, timedelta
from models import WeatherData, EnergyProduction, SolarPlant, MLPrediction, ModelPerformance
from app import db

class SolarMLPredictor:
    def __init__(self):
        self.rf_model = None
        self.xgb_model = None
        self.scaler = StandardScaler()
        self.feature_columns = [
            'temperature', 'humidity', 'cloud_cover', 'wind_speed', 
            'solar_irradiance', 'equipment_efficiency', 'plant_capacity',
            'days_since_maintenance', 'season_monsoon', 'season_winter', 'season_summer'
        ]
        self.models_dir = 'saved_models'
        os.makedirs(self.models_dir, exist_ok=True)
        
    def prepare_training_data(self, plant_id=None):
        """Prepare training data from database"""
        try:
            # Query for historical data
            query = db.session.query(
                WeatherData.temperature,
                WeatherData.humidity,
                WeatherData.cloud_cover,
                WeatherData.wind_speed,
                WeatherData.solar_irradiance,
                EnergyProduction.equipment_efficiency,
                EnergyProduction.energy_produced,
                EnergyProduction.revenue_inr,
                SolarPlant.capacity_mw,
                WeatherData.date
            ).join(
                EnergyProduction, WeatherData.plant_id == EnergyProduction.plant_id
            ).join(
                SolarPlant, WeatherData.plant_id == SolarPlant.id
            ).filter(
                WeatherData.date == EnergyProduction.date
            )
            
            if plant_id:
                query = query.filter(WeatherData.plant_id == plant_id)
                
            data = query.all()
            
            if not data:
                logging.warning("No training data found")
                return None, None, None
                
            # Convert to DataFrame
            df = pd.DataFrame(data, columns=[
                'temperature', 'humidity', 'cloud_cover', 'wind_speed',
                'solar_irradiance', 'equipment_efficiency', 'energy_produced',
                'revenue_inr', 'plant_capacity', 'date'
            ])
            
            # Convert date column to datetime
            df['date'] = pd.to_datetime(df['date'])
            
            # Feature engineering
            df = self._add_features(df)
            
            # Prepare features and targets
            X = df[self.feature_columns]
            y_energy = df['energy_produced']
            y_revenue = df['revenue_inr']
            
            return X, y_energy, y_revenue
            
        except Exception as e:
            logging.error(f"Error preparing training data: {e}")
            return None, None, None
    
    def _add_features(self, df):
        """Add engineered features"""
        # Days since maintenance (simplified - assume monthly maintenance)
        df['days_since_maintenance'] = (df['date'].dt.day % 30)
        
        # Seasonal features
        df['month'] = df['date'].dt.month
        df['season_monsoon'] = ((df['month'] >= 6) & (df['month'] <= 9)).astype(int)
        df['season_winter'] = ((df['month'] >= 11) | (df['month'] <= 2)).astype(int)
        df['season_summer'] = ((df['month'] >= 3) & (df['month'] <= 5)).astype(int)
        
        return df
    
    def train_models(self, plant_id=None):
        """Train both Random Forest and XGBoost models"""
        try:
            X, y_energy, y_revenue = self.prepare_training_data(plant_id)
            
            if X is None:
                logging.error("No training data available")
                return False
                
            # Split data
            X_train, X_test, y_energy_train, y_energy_test = train_test_split(
                X, y_energy, test_size=0.2, random_state=42
            )
            
            # Scale features
            X_train_scaled = self.scaler.fit_transform(X_train)
            X_test_scaled = self.scaler.transform(X_test)
            
            # Train Random Forest
            self.rf_model = RandomForestRegressor(
                n_estimators=100,
                max_depth=10,
                random_state=42,
                n_jobs=-1
            )
            self.rf_model.fit(X_train_scaled, y_energy_train)
            
            # Train XGBoost
            self.xgb_model = xgb.XGBRegressor(
                n_estimators=100,
                max_depth=6,
                learning_rate=0.1,
                random_state=42
            )
            self.xgb_model.fit(X_train_scaled, y_energy_train)
            
            # Evaluate models
            rf_predictions = self.rf_model.predict(X_test_scaled)
            xgb_predictions = self.xgb_model.predict(X_test_scaled)
            
            # Calculate metrics
            rf_metrics = self._calculate_metrics(y_energy_test, rf_predictions)
            xgb_metrics = self._calculate_metrics(y_energy_test, xgb_predictions)
            
            # Save model performance
            self._save_model_performance('Random Forest', rf_metrics, len(X))
            self._save_model_performance('XGBoost', xgb_metrics, len(X))
            
            # Save models
            self._save_models()
            
            logging.info("Models trained successfully")
            logging.info(f"Random Forest R²: {rf_metrics['r2']:.3f}")
            logging.info(f"XGBoost R²: {xgb_metrics['r2']:.3f}")
            
            return True
            
        except Exception as e:
            logging.error(f"Error training models: {e}")
            return False
    
    def _calculate_metrics(self, y_true, y_pred):
        """Calculate model performance metrics"""
        return {
            'rmse': np.sqrt(mean_squared_error(y_true, y_pred)),
            'mae': mean_absolute_error(y_true, y_pred),
            'r2': r2_score(y_true, y_pred)
        }
    
    def _save_model_performance(self, model_name, metrics, dataset_size):
        """Save model performance to database"""
        try:
            performance = ModelPerformance(
                model_name=model_name,
                accuracy_score=metrics['r2'],
                rmse=metrics['rmse'],
                mae=metrics['mae'],
                r2_score=metrics['r2'],
                dataset_size=dataset_size
            )
            db.session.add(performance)
            db.session.commit()
        except Exception as e:
            logging.error(f"Error saving model performance: {e}")
    
    def _save_models(self):
        """Save trained models to disk"""
        try:
            if self.rf_model:
                joblib.dump(self.rf_model, os.path.join(self.models_dir, 'random_forest.pkl'))
            if self.xgb_model:
                joblib.dump(self.xgb_model, os.path.join(self.models_dir, 'xgboost.pkl'))
            joblib.dump(self.scaler, os.path.join(self.models_dir, 'scaler.pkl'))
            logging.info("Models saved successfully")
        except Exception as e:
            logging.error(f"Error saving models: {e}")
    
    def load_models(self):
        """Load trained models from disk"""
        try:
            rf_path = os.path.join(self.models_dir, 'random_forest.pkl')
            xgb_path = os.path.join(self.models_dir, 'xgboost.pkl')
            scaler_path = os.path.join(self.models_dir, 'scaler.pkl')
            
            if os.path.exists(rf_path):
                self.rf_model = joblib.load(rf_path)
            if os.path.exists(xgb_path):
                self.xgb_model = joblib.load(xgb_path)
            if os.path.exists(scaler_path):
                self.scaler = joblib.load(scaler_path)
                
            return True
        except Exception as e:
            logging.error(f"Error loading models: {e}")
            return False
    
    def predict_6_months(self, plant_id, weather_forecast=None):
        """Generate 6-month predictions"""
        try:
            if not self.rf_model or not self.xgb_model:
                if not self.load_models():
                    logging.error("No trained models available")
                    return None
            
            # Get plant information
            plant = SolarPlant.query.get(plant_id)
            if not plant:
                logging.error(f"Plant {plant_id} not found")
                return None
            
            predictions = []
            start_date = datetime.now().date()
            
            for i in range(180):  # 6 months = 180 days
                pred_date = start_date + timedelta(days=i)
                
                # Create feature vector (simplified - would use weather forecast in production)
                features = self._create_prediction_features(plant, pred_date, weather_forecast)
                
                if features is not None:
                    features_scaled = self.scaler.transform([features])
                    
                    # Get predictions from both models
                    if self.rf_model is None or self.xgb_model is None:
                        logging.error("Models not loaded. Training required.")
                        continue
                        
                    rf_pred = self.rf_model.predict(features_scaled)[0]
                    xgb_pred = self.xgb_model.predict(features_scaled)[0]
                    
                    # Ensemble prediction (average)
                    energy_pred = (rf_pred + xgb_pred) / 2
                    
                    # Calculate revenue (typical Indian solar tariff)
                    tariff_rate = np.random.uniform(3.5, 5.5)  # INR per kWh
                    revenue_pred = energy_pred * tariff_rate
                    
                    # Calculate efficiency
                    max_possible = plant.capacity_mw * 1000 * 8  # Assuming 8 hours peak sun
                    efficiency_pred = min(100, (energy_pred / max_possible) * 100)
                    
                    # Confidence score (simplified)
                    confidence = np.random.uniform(0.75, 0.95)
                    
                    predictions.append({
                        'date': pred_date,
                        'energy': energy_pred,
                        'revenue': revenue_pred,
                        'efficiency': efficiency_pred,
                        'confidence': confidence
                    })
            
            # Save predictions to database
            self._save_predictions(plant_id, predictions)
            
            return predictions
            
        except Exception as e:
            logging.error(f"Error generating predictions: {e}")
            return None
    
    def _create_prediction_features(self, plant, pred_date, weather_forecast=None):
        """Create feature vector for prediction"""
        try:
            # Get recent historical data for baseline
            recent_weather = WeatherData.query.filter(
                WeatherData.plant_id == plant.id
            ).order_by(WeatherData.date.desc()).first()
            
            recent_production = EnergyProduction.query.filter(
                EnergyProduction.plant_id == plant.id
            ).order_by(EnergyProduction.date.desc()).first()
            
            if not recent_weather or not recent_production:
                return None
            
            # Use recent data as baseline (in production, would use weather forecast)
            month = pred_date.month
            
            # Seasonal adjustments for Indian climate
            if 6 <= month <= 9:  # Monsoon
                temp_factor = 0.9
                irradiance_factor = 0.7
                humidity_factor = 1.3
                cloud_factor = 1.5
            elif 11 <= month <= 2:  # Winter
                temp_factor = 0.8
                irradiance_factor = 0.8
                humidity_factor = 0.7
                cloud_factor = 0.9
            else:  # Summer
                temp_factor = 1.1
                irradiance_factor = 1.0
                humidity_factor = 0.6
                cloud_factor = 0.8
            
            features = [
                recent_weather.temperature * temp_factor,  # temperature
                recent_weather.humidity * humidity_factor,  # humidity
                recent_weather.cloud_cover * cloud_factor,  # cloud_cover
                recent_weather.wind_speed,  # wind_speed
                recent_weather.solar_irradiance * irradiance_factor,  # solar_irradiance
                recent_production.equipment_efficiency * 0.995,  # slight degradation
                plant.capacity_mw,  # plant_capacity
                pred_date.day % 30,  # days_since_maintenance
                1 if 6 <= month <= 9 else 0,  # season_monsoon
                1 if 11 <= month <= 2 or month <= 2 else 0,  # season_winter
                1 if 3 <= month <= 5 else 0,  # season_summer
            ]
            
            return features
            
        except Exception as e:
            logging.error(f"Error creating prediction features: {e}")
            return None
    
    def _save_predictions(self, plant_id, predictions):
        """Save predictions to database"""
        try:
            # Clear old predictions
            MLPrediction.query.filter(MLPrediction.plant_id == plant_id).delete()
            
            # Save new predictions
            for pred in predictions:
                prediction = MLPrediction(
                    plant_id=plant_id,
                    prediction_date=pred['date'],
                    predicted_energy=pred['energy'],
                    predicted_revenue=pred['revenue'],
                    predicted_efficiency=pred['efficiency'],
                    confidence_score=pred['confidence'],
                    model_used='Ensemble (RF+XGB)'
                )
                db.session.add(prediction)
            
            db.session.commit()
            logging.info(f"Saved {len(predictions)} predictions for plant {plant_id}")
            
        except Exception as e:
            logging.error(f"Error saving predictions: {e}")
            db.session.rollback()

# Global predictor instance
ml_predictor = SolarMLPredictor()
